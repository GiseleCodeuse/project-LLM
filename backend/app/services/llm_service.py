import os
import asyncio
from dotenv import load_dotenv
from google import genai

load_dotenv()

API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    raise RuntimeError("‚ùå Cl√© API Gemini manquante dans le fichier .env")

# Initialiser le client
client = genai.Client(api_key=API_KEY)

# Conseil : gemini-2.0-flash est tr√®s demand√©. 
# Si tu es souvent bloqu√©, essaie "gemini-1.5-flash" qui a des quotas plus souples.
MODEL_NAME = "gemini-2.0-flash" 

SYSTEM_PROMPT = (
    "Tu es une assistante cosm√©tique IA experte, bienveillante et p√©dagogique üíñ.\n"
    "Tutoiement obligatoire.\n"
    "Ton r√¥le : conseiller les utilisateurs sur la peau, d√©tecter le type de peau et les imperfections, "
    "et proposer des solutions naturelles ou des produits cosm√©tiques adapt√©s üåø.\n\n"
    "R√®gles :\n"
    "1Ô∏è‚É£ Salutations : r√©ponds de mani√®re courte, chaleureuse et pr√©sente-toi bri√®vement üòÑ.\n"
    "2Ô∏è‚É£ Inconnu : si tu ne sais pas, dis-le gentiment et conseille un pro üòÖ.\n"
    "Structure obligatoire pour les diagnostics :\n"
    "Observation üëÄ : ...\n"
    "Explication üìù : ...\n"
    "Conseils üí° : ...\n"
    "Question ‚ùì : ...\n"
)

async def get_llm_response(message: str) -> str:
    # --- 1. GESTION DES SALUTATIONS (SANS API) ---
    # On g√®re les bonjours ici pour √©conomiser le quota journalier
    salutations = ["bonjour", "salut", "hello", "coucou", "hi", "d√©but", "commencer"]
    if message.lower().strip() in salutations:
        return (
            "Coucou ! ‚ú® Bienvenue, je suis ton assistante en beaut√© de la peau. "
            "Je suis l√† pour t'aider √† d√©tecter ton type de peau, tes imperfections "
            "et te proposer des solutions adapt√©es. Comment puis-je t'aider aujourd'hui ? üå∏"
        )

    # --- 2. APPEL √Ä L'API AVEC GESTION D'ERREUR ---
    try:
        # Appel √† l'API
        response = client.models.generate_content(
            model=MODEL_NAME, 
            config={
                "system_instruction": SYSTEM_PROMPT,
                "temperature": 0.7,
            },
            contents=message
        )

        # Extraction du texte
        if response and response.text:
            return response.text
        
        return "Je n'ai pas pu g√©n√©rer de r√©ponse, peux-tu reformuler ? ü§î"

    except Exception as e:
        error_msg = str(e)
        print(f"Erreur lors de l'appel Gemini: {error_msg}")
        
        # --- 3. TES MESSAGES PERSONNALIS√âS ---
        
        # Erreur de quota (Limite atteinte)
        if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
            return "Oups ! Je re√ßois trop de messages d'un coup ! R√©essaie dans 30 secondes üå∏. (Le quota gratuit est temporairement √©puis√©)"

        # Erreur de mod√®le (404)
        if "404" in error_msg:
            return "D√©sol√©e, mon cerveau technique fait des siennes (Mod√®le introuvable) üõ†Ô∏è."

        # Erreur g√©n√©rique
        return "Petit souci technique avec l'IA... Repasse me voir dans un instant, je me repoudre le nez ! üíÑ‚ú®"

# Exemple d'utilisation (si tu lances le script directement)
if __name__ == "__main__":
    async def test():
        print(await get_llm_response("Bonjour"))
    asyncio.run(test())